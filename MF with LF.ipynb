{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems in keras :\n",
    "In this notebook, we will make a recommender system using Matrix factorization.<br/>\n",
    "Problem Formulation :<br/>\n",
    "Given a set of users 'U' and items 'I' and their ratings 'R' by users for items in 'I'. <br/>\n",
    "Thus, Ratings data D ⊆ U × I × R <br/>\n",
    "Rating data D are typically represented as a sparse matrix R ∈ R^<sup>|U|×|I|</sup> <br/>\n",
    "The ratings matrix 'R' thus looks like the following :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratings matrix R is usually partially observed:\n",
    "* No user is able to rate all items\n",
    "* Most of the items are not rated by all users<br/>\n",
    "We can estimate the factorization of a matrix from some observations to<br/>\n",
    "predict its unobserved part as shown below : \n",
    "![title](image83.png)\n",
    "\n",
    "* Each item i ∈ I is associated with a latent feature vector Q<sub>i</sub> ∈ R<sup> K</sup>\n",
    "* Each user u ∈ U is associated with a latent feature vector P<sub>u</sub> ∈  R<sup> K</sup>\n",
    "* Each entry in the original matrix can be estimated by : <br/>\n",
    "<br/>\n",
    "  \\begin{equation*}\n",
    "  \\hat{r}_{u,i} = P_u^T Q_i = \\sum_{k=1}^{K} P_{u,k} Q_{i,k}\n",
    "  \\end{equation*}\n",
    "  \n",
    "  \n",
    "* Thus the task is to approximate two matrices P and Q which corresponds to the user and item latent features respectively. How? \n",
    "* To approximate we need an objective function which can be the squared loss between the original and predicted ratings.<br/>\n",
    "  Thus the loss function is : \n",
    " \\begin{equation*}\n",
    " L  = \\sum_{u,i,r_{u,i} ∈ D^{train}}  (r_{u,i} - \\hat{r}_{u,i})^2 \n",
    "  \\end{equation*}\n",
    "  \n",
    "* Task  : <br/>\n",
    " \\begin{equation*}\n",
    "  arg min { L  = \\sum_{u,i,r_{u,i} ∈ D^{train}}  (r_{u,i} - \\hat{r}_{u,i})^2 }\n",
    "  \\end{equation*}\n",
    "  \n",
    "  D<sup>train</sup> = Training data\n",
    "\n",
    "Once the model is formed in keras, we can use any optimization algorithm <br/>like stochastic gradient descent or adam to backpropagate and update the<br/> values in latent feature matrix P and Q to most closely match the ratings values in R.\n",
    "<br/>Or in other words, the **mean squared error** between original and predicted ratings is minimum.<br/>\n",
    "\n",
    "\n",
    "* In this tutorial we will use two methods : \n",
    "  * Matrix factorization using keras\n",
    "  * Neural network approach to learn linear relationships from the latent feature vectors.\n",
    "<br/>\n",
    "* We will use **Embeddings layer** in keras to avoid approximating the matrix of size U * I which is generally too sparse. <br/>Detailed explanation on Embeddings and references are included later in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets start with reading the dataset and preprocessing : \n",
    "For now we will consider only the ratings.dat file from movie lens. Later we will add more features of user and items to the latent matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import pivot_table as pivot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ratings.csv',error_bad_lines=True)\n",
    "#shuffle the datasets \n",
    "df = df.sample(frac=1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99778</th>\n",
       "      <td>667</td>\n",
       "      <td>446</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847271818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16170</th>\n",
       "      <td>104</td>\n",
       "      <td>71135</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1446674062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>19</td>\n",
       "      <td>1394</td>\n",
       "      <td>5.0</td>\n",
       "      <td>855192061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55070</th>\n",
       "      <td>395</td>\n",
       "      <td>671</td>\n",
       "      <td>5.0</td>\n",
       "      <td>953007109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>187</td>\n",
       "      <td>953</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1230361942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "99778     667      446     4.0   847271818\n",
       "16170     104    71135     3.5  1446674062\n",
       "3521       19     1394     5.0   855192061\n",
       "55070     395      671     5.0   953007109\n",
       "25477     187      953     3.0  1230361942"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We assign a unique number between (0, #users) to each user and do the same for movies.<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99778</th>\n",
       "      <td>666</td>\n",
       "      <td>395</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847271818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16170</th>\n",
       "      <td>103</td>\n",
       "      <td>7295</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1446674062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>18</td>\n",
       "      <td>1132</td>\n",
       "      <td>5.0</td>\n",
       "      <td>855192061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55070</th>\n",
       "      <td>394</td>\n",
       "      <td>575</td>\n",
       "      <td>5.0</td>\n",
       "      <td>953007109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>186</td>\n",
       "      <td>773</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1230361942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "99778     666      395     4.0   847271818\n",
       "16170     103     7295     3.5  1446674062\n",
       "3521       18     1132     5.0   855192061\n",
       "55070     394      575     5.0   953007109\n",
       "25477     186      773     3.0  1230361942"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.userId = df.userId.astype('category').cat.codes.values   #Numpy array of user id's\n",
    "df.movieId = df.movieId.astype('category').cat.codes.values  #Numpy array for item id's\n",
    "# df['userId'] = df.user_id\n",
    "# df['movieId'] = df.item_id\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9056</th>\n",
       "      <th>9057</th>\n",
       "      <th>9058</th>\n",
       "      <th>9059</th>\n",
       "      <th>9060</th>\n",
       "      <th>9061</th>\n",
       "      <th>9062</th>\n",
       "      <th>9063</th>\n",
       "      <th>9064</th>\n",
       "      <th>9065</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 9066 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  0     1     2     3     4     5     6     7     8     9     ...   \\\n",
       "userId                                                               ...    \n",
       "0         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   4.0  ...    \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   4.0  ...    \n",
       "4         NaN   NaN   4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "6         3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   3.0  ...    \n",
       "7         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "8         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "9         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "10        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "11        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "12        5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "13        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "14        2.0   2.0   NaN   NaN   4.5   4.0   NaN   NaN   NaN   3.0  ...    \n",
       "15        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "16        NaN   NaN   NaN   NaN   NaN   4.5   NaN   NaN   NaN   NaN  ...    \n",
       "17        NaN   NaN   NaN   NaN   3.0   4.0   3.0   NaN   3.0   NaN  ...    \n",
       "18        3.0   3.0   3.0   3.0   NaN   3.0   3.0   NaN   3.0   3.0  ...    \n",
       "19        3.5   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "20        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   3.0  ...    \n",
       "21        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "22        3.0   NaN   NaN   NaN   NaN   3.5   NaN   NaN   NaN   NaN  ...    \n",
       "23        NaN   NaN   NaN   NaN   NaN   5.0   NaN   NaN   NaN   NaN  ...    \n",
       "24        NaN   NaN   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "25        5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "26        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "27        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "28        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "29        4.0   2.0   NaN   NaN   NaN   4.0   NaN   4.0   NaN   NaN  ...    \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    \n",
       "641       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "642       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "643       NaN   NaN   NaN   1.0   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "644       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "645       5.0   NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "646       4.0   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN   NaN  ...    \n",
       "647       NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN   NaN  ...    \n",
       "648       4.0   NaN   NaN   3.0   NaN   NaN   NaN   NaN   NaN   5.0  ...    \n",
       "649       NaN   NaN   3.0   1.0   3.0   NaN   NaN   NaN   NaN   4.0  ...    \n",
       "650       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "651       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "652       4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "653       5.0   3.0   NaN   NaN   4.0   NaN   NaN   NaN   NaN   4.0  ...    \n",
       "654       NaN   4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "655       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "656       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "657       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "658       NaN   NaN   NaN   NaN   NaN   3.0   NaN   NaN   NaN   NaN  ...    \n",
       "659       2.5   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "660       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "661       NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   3.0  ...    \n",
       "662       4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "663       3.5   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN   NaN  ...    \n",
       "664       NaN   3.0   3.0   NaN   3.0   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "665       NaN   NaN   NaN   NaN   NaN   5.0   NaN   NaN   NaN   3.0  ...    \n",
       "666       NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN   NaN  ...    \n",
       "667       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "668       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "669       4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "670       5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "\n",
       "movieId  9056  9057  9058  9059  9060  9061  9062  9063  9064  9065  \n",
       "userId                                                               \n",
       "0         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "7         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "8         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "9         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "10        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "11        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "12        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "13        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "14        NaN   0.5   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "15        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "16        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "17        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "18        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "19        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "20        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "21        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "22        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "23        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "24        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "25        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "26        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "27        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "28        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "29        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "641       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "642       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "643       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "644       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "645       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "646       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "647       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "648       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "649       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "650       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "651       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "652       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "653       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "654       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "655       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "656       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "657       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "658       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "659       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "660       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "661       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "662       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "663       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "664       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "665       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "666       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "667       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "668       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "669       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "670       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[671 rows x 9066 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pivot(df,values= 'rating',index = 'userId',columns='movieId')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the above cell we can see the rating matrix D of size 671 users × 9066 movies. But as we will use Embeddings for this task we do not need to decompose the matrix of this big size.\n",
    "\n",
    "* Dividing the dataframe into train and test: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86585</th>\n",
       "      <td>579</td>\n",
       "      <td>498</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1167159391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98434</th>\n",
       "      <td>658</td>\n",
       "      <td>197</td>\n",
       "      <td>3.0</td>\n",
       "      <td>835642424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13756</th>\n",
       "      <td>87</td>\n",
       "      <td>7030</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1239775107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73008</th>\n",
       "      <td>508</td>\n",
       "      <td>3229</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1037842687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7733</th>\n",
       "      <td>47</td>\n",
       "      <td>7379</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1414562131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "86585     579      498     3.5  1167159391\n",
       "98434     658      197     3.0   835642424\n",
       "13756      87     7030     4.5  1239775107\n",
       "73008     508     3229     3.0  1037842687\n",
       "7733       47     7379     3.0  1414562131"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Matrix factorization using keras : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies are: 9066\n",
      "Number of users are: 671\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "num_users = len(df.userId.unique())\n",
    "num_movies = len(df.movieId.unique())\n",
    "n_latent_factors = 3      #Hyperparameter\n",
    "print(\"Number of movies are:\",num_movies)\n",
    "print(\"Number of users are:\",num_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Before we start to form a keras model for matrix factorization lets dive into the concept of using low dimensional **embedding** instead of the ratings matrix R. \n",
    "* **Why to use embeddings ? **\n",
    "  * One-hot encoded vectors are high-dimensional and sparse. Lets take the example of movie lens dataset. We have around 700 users and 9000 items. Thus, when using one hot encoding or pivot matrix as shown above, we have a matrix of size ~700   * 9000.This means that, when using pivot, each user item pair will be represented by a vector containing 9000 integers. And suppose the user has rated only one 10 items, then 8990 of these integers are zeros. In a big dataset this approach is not computationally efficient.\n",
    "  * The vectors of each embedding get updated while training the neural network. This allows us to visualize relationships between users and items, but also between everything that can be turned into a vector through an embedding layer. Thus we can generate embeddings for indexes of users' or items' features such as occupation, age, genre etc. even after including more features the vector will still be low-dimensional.\n",
    "  \n",
    "What exactly is the input and output of the embedding layer?  To understand this lets use the embedding layer for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Creating a sample sequential model\"\n",
    "model = Sequential()\n",
    "\n",
    "\"Embedding layer > input_dim = dimension of input vector \"\n",
    "\"                  output_dim = Number of latent features \"\n",
    "model.add(keras.layers.Embedding(input_dim=num_movies+1,output_dim=n_latent_factors , input_length=1))\n",
    "\"the model will take as input an integer matrix of size (batch, input_length).\"\n",
    "\" We input the item_id in the range 1 - 9066 of shape [1] and get output of shape [1 * n_latent_factors]\"\n",
    "input_array =df.item_id\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input to the embedding layer (100004,)\n",
      "shape of output to the embedding layer (100004, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of input to the embedding layer\", df.item_id.shape)\n",
    "print(\"shape of output to the embedding layer\",output_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_array_reshaped=output_array.reshape((100004,3))\n",
    "df_movies_with_latent_factors = pd.DataFrame(output_array_reshaped,index=df.item_id,columns=['LF1','LF2','LF3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LF1</th>\n",
       "      <th>LF2</th>\n",
       "      <th>LF3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-0.038270</td>\n",
       "      <td>-0.045317</td>\n",
       "      <td>-0.008740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7295</th>\n",
       "      <td>-0.006597</td>\n",
       "      <td>0.045694</td>\n",
       "      <td>-0.041967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>-0.042058</td>\n",
       "      <td>0.038397</td>\n",
       "      <td>-0.049588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>-0.032411</td>\n",
       "      <td>0.028631</td>\n",
       "      <td>0.031273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>-0.045801</td>\n",
       "      <td>0.011517</td>\n",
       "      <td>0.024187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LF1       LF2       LF3\n",
       "395  -0.038270 -0.045317 -0.008740\n",
       "7295 -0.006597  0.045694 -0.041967\n",
       "1132 -0.042058  0.038397 -0.049588\n",
       "575  -0.032411  0.028631  0.031273\n",
       "773  -0.045801  0.011517  0.024187"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies_with_latent_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_movies_with_latent_factors.to_csv('moviesEmbeddings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Thus the embedding layer has converted each item index to a random number vector of the given output shape(latent features).\n",
    "<br/>\n",
    "\n",
    "* Doing the same for users indexes we will have similar matrix. \n",
    "* These embedding matrices correspond to the matrix P and Q discussed above.\n",
    "* Thus next steps to be done are : \n",
    "    * Dot product of P and Q to predict ratings of all users for all items\n",
    "    * Optimizing over the loss between predicted and actual ratings and update P and Q values to get more closer to actual ratings.\n",
    "    * Stop training when loss is less and then use P and Q matrices to predict rating R for any user U to item I using:\n",
    "  \\begin{equation*}\n",
    "  \\hat{r}_{u,i} = P_u^T Q_i = \\sum_{k=1}^{K} P_{u,k} Q_{i,k}\n",
    "  \\end{equation*}\n",
    "  \n",
    "  Where : K = number of Latent features\n",
    "\n",
    "\n",
    "To read more about embedding layers, here is a blogpost for reference : https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets begin the keras model for matrix factorization : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99778</th>\n",
       "      <td>666</td>\n",
       "      <td>395</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847271818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16170</th>\n",
       "      <td>103</td>\n",
       "      <td>7295</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1446674062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>18</td>\n",
       "      <td>1132</td>\n",
       "      <td>5.0</td>\n",
       "      <td>855192061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55070</th>\n",
       "      <td>394</td>\n",
       "      <td>575</td>\n",
       "      <td>5.0</td>\n",
       "      <td>953007109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>186</td>\n",
       "      <td>773</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1230361942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "99778     666      395     4.0   847271818\n",
       "16170     103     7295     3.5  1446674062\n",
       "3521       18     1132     5.0   855192061\n",
       "55070     394      575     5.0   953007109\n",
       "25477     186      773     3.0  1230361942"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import non_neg\n",
    "\n",
    "\"Latent feature vector for movies\"\n",
    "movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "movie_embedding = keras.layers.Embedding(num_movies + 1, n_latent_factors, name='NonNegMovie-Embedding', embeddings_constraint=non_neg())(movie_input)\n",
    "movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "\n",
    "\"Latent feature vector for users\"\n",
    "user_input = keras.layers.Input(shape=[1],name='User')\n",
    "user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(num_users + 1, n_latent_factors,name='NonNegUser-Embedding',embeddings_constraint=non_neg())(user_input))\n",
    "\n",
    "\"Merge the user and movie latent vectors using dot product\"\n",
    "prod = keras.layers.merge([movie_vec, user_vec], mode='dot',name='DotProduct')\n",
    "\n",
    "\"Build model and compile\"\n",
    "model_vanilla_MF = keras.Model([user_input, movie_input], prod)\n",
    "\n",
    "\"Using Adam optimizer to backpropagate\"\n",
    "model_vanilla_MF.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Item (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "User (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NonNegMovie-Embedding (Embeddin (None, 1, 3)         27201       Item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "NonNegUser-Embedding (Embedding (None, 1, 3)         2016        User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "FlattenMovies (Flatten)         (None, 3)            0           NonNegMovie-Embedding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUsers (Flatten)          (None, 3)            0           NonNegUser-Embedding[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "DotProduct (Merge)              (None, 1)            0           FlattenMovies[0][0]              \n",
      "                                                                 FlattenUsers[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 29,217\n",
      "Trainable params: 29,217\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vanilla_MF.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model takes two inputs  : <br/> 1. Item input (Q) which is the movie latent feature <br/> 2. User input (P) for users latent features <br/>\n",
    "* Then the movie and user embeddings are created. \n",
    "* The embeddings are then flattened and merged using **dot** product.\n",
    "* Then we will have the predicted rating matrix *R* \n",
    "* Error is then calcuated, which is this case is \"mean squared error\"\n",
    "* Backpropagate and update P and Q using ADAM to minimize this error. Once the error is low we can say the predicted ratings are close to the actual ratings. \n",
    "* ** Now lets begin training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77482</th>\n",
       "      <td>535</td>\n",
       "      <td>393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>829471720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94404</th>\n",
       "      <td>623</td>\n",
       "      <td>4670</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1262200449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76847</th>\n",
       "      <td>531</td>\n",
       "      <td>4098</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1076971785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20490</th>\n",
       "      <td>136</td>\n",
       "      <td>1575</td>\n",
       "      <td>4.0</td>\n",
       "      <td>946411720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15177</th>\n",
       "      <td>98</td>\n",
       "      <td>1263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>938586764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "77482     535      393     1.0   829471720\n",
       "94404     623     4670     0.5  1262200449\n",
       "76847     531     4098     2.5  1076971785\n",
       "20490     136     1575     4.0   946411720\n",
       "15177      98     1263     1.0   938586764"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" Lets see the values we will use to input\" \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72002 samples, validate on 8001 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.6040 - val_loss: 1.2527\n",
      "Epoch 2/50\n",
      " - 3s - loss: 0.6010 - val_loss: 1.2570\n",
      "Epoch 3/50\n",
      " - 3s - loss: 0.5978 - val_loss: 1.2613\n",
      "Epoch 4/50\n",
      " - 4s - loss: 0.5949 - val_loss: 1.2653\n",
      "Epoch 5/50\n",
      " - 3s - loss: 0.5922 - val_loss: 1.2672\n",
      "Epoch 6/50\n",
      " - 3s - loss: 0.5895 - val_loss: 1.2715\n",
      "Epoch 7/50\n",
      " - 3s - loss: 0.5870 - val_loss: 1.2741\n",
      "Epoch 8/50\n",
      " - 3s - loss: 0.5853 - val_loss: 1.2749\n",
      "Epoch 9/50\n",
      " - 3s - loss: 0.5828 - val_loss: 1.2800\n",
      "Epoch 10/50\n",
      " - 3s - loss: 0.5806 - val_loss: 1.2816\n",
      "Epoch 11/50\n",
      " - 4s - loss: 0.5785 - val_loss: 1.2865\n",
      "Epoch 12/50\n",
      " - 3s - loss: 0.5764 - val_loss: 1.2874\n",
      "Epoch 13/50\n",
      " - 3s - loss: 0.5742 - val_loss: 1.2888\n",
      "Epoch 14/50\n",
      " - 3s - loss: 0.5726 - val_loss: 1.2903\n",
      "Epoch 15/50\n",
      " - 4s - loss: 0.5710 - val_loss: 1.2936\n",
      "Epoch 16/50\n",
      " - 4s - loss: 0.5692 - val_loss: 1.2947\n",
      "Epoch 17/50\n",
      " - 4s - loss: 0.5674 - val_loss: 1.2980\n",
      "Epoch 18/50\n",
      " - 4s - loss: 0.5660 - val_loss: 1.3011\n",
      "Epoch 19/50\n",
      " - 3s - loss: 0.5644 - val_loss: 1.3010\n",
      "Epoch 20/50\n",
      " - 4s - loss: 0.5627 - val_loss: 1.3023\n",
      "Epoch 21/50\n",
      " - 4s - loss: 0.5613 - val_loss: 1.3040\n",
      "Epoch 22/50\n",
      " - 4s - loss: 0.5596 - val_loss: 1.3071\n",
      "Epoch 23/50\n",
      " - 4s - loss: 0.5586 - val_loss: 1.3058\n",
      "Epoch 24/50\n",
      " - 4s - loss: 0.5570 - val_loss: 1.3101\n",
      "Epoch 25/50\n",
      " - 4s - loss: 0.5557 - val_loss: 1.3110\n",
      "Epoch 26/50\n",
      " - 4s - loss: 0.5545 - val_loss: 1.3118\n",
      "Epoch 27/50\n",
      " - 4s - loss: 0.5533 - val_loss: 1.3129\n",
      "Epoch 28/50\n",
      " - 3s - loss: 0.5522 - val_loss: 1.3131\n",
      "Epoch 29/50\n",
      " - 4s - loss: 0.5511 - val_loss: 1.3154\n",
      "Epoch 30/50\n",
      " - 4s - loss: 0.5497 - val_loss: 1.3175\n",
      "Epoch 31/50\n",
      " - 4s - loss: 0.5485 - val_loss: 1.3174\n",
      "Epoch 32/50\n",
      " - 3s - loss: 0.5475 - val_loss: 1.3195\n",
      "Epoch 33/50\n",
      " - 4s - loss: 0.5464 - val_loss: 1.3212\n",
      "Epoch 34/50\n",
      " - 4s - loss: 0.5454 - val_loss: 1.3235\n",
      "Epoch 35/50\n",
      " - 3s - loss: 0.5445 - val_loss: 1.3241\n",
      "Epoch 36/50\n",
      " - 4s - loss: 0.5436 - val_loss: 1.3224\n",
      "Epoch 37/50\n",
      " - 4s - loss: 0.5424 - val_loss: 1.3256\n",
      "Epoch 38/50\n",
      " - 4s - loss: 0.5416 - val_loss: 1.3254\n",
      "Epoch 39/50\n",
      " - 4s - loss: 0.5407 - val_loss: 1.3260\n",
      "Epoch 40/50\n",
      " - 3s - loss: 0.5397 - val_loss: 1.3294\n",
      "Epoch 41/50\n",
      " - 3s - loss: 0.5391 - val_loss: 1.3290\n",
      "Epoch 42/50\n",
      " - 4s - loss: 0.5381 - val_loss: 1.3286\n",
      "Epoch 43/50\n",
      " - 4s - loss: 0.5376 - val_loss: 1.3299\n",
      "Epoch 44/50\n",
      " - 3s - loss: 0.5366 - val_loss: 1.3308\n",
      "Epoch 45/50\n",
      " - 3s - loss: 0.5359 - val_loss: 1.3311\n",
      "Epoch 46/50\n",
      " - 4s - loss: 0.5349 - val_loss: 1.3320\n",
      "Epoch 47/50\n",
      " - 4s - loss: 0.5345 - val_loss: 1.3323\n",
      "Epoch 48/50\n",
      " - 4s - loss: 0.5338 - val_loss: 1.3319\n",
      "Epoch 49/50\n",
      " - 4s - loss: 0.5329 - val_loss: 1.3338\n",
      "Epoch 50/50\n",
      " - 4s - loss: 0.5323 - val_loss: 1.3348\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "history = model_vanilla_MF.fit([train.userId, train.movieId], train.rating, epochs=50, verbose=2,validation_split=0.1,\n",
    "                               callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fed87d17208>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEKCAYAAADNSVhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed87ceae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(history.history['loss']).plot(logy=True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train Error\")\n",
    "# history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test = np.stack((test.userId,test.movieId),axis = 1)\n",
    "# print(x_test)\n",
    "\n",
    "y_hat = np.round(model_vanilla_MF.predict([test.userId, test.movieId]),decimals=0)\n",
    "\n",
    "y_true = test.rating\n",
    "y_true = np.array(test.rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81823408829558519"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()\n",
    "test['perdicted ratings']=y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted ratings: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>perdicted ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55624</th>\n",
       "      <td>401</td>\n",
       "      <td>5478</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1443394485</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97830</th>\n",
       "      <td>653</td>\n",
       "      <td>2531</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1145390304</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57207</th>\n",
       "      <td>411</td>\n",
       "      <td>3226</td>\n",
       "      <td>2.0</td>\n",
       "      <td>993086634</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9041</th>\n",
       "      <td>57</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>961127761</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30882</th>\n",
       "      <td>219</td>\n",
       "      <td>870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>970507667</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp  perdicted ratings\n",
       "55624     401     5478     3.0  1443394485                3.0\n",
       "97830     653     2531     5.0  1145390304                5.0\n",
       "57207     411     3226     2.0   993086634                3.0\n",
       "9041       57     2019     2.0   961127761                2.0\n",
       "30882     219      870     4.0   970507667                4.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"predicted ratings: \")\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Thus, we did matrix factorization using keras to approximate the ratings matrix. <br/>\n",
    "Next, let's build a neural network model to implement recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender systems :  Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_factors_user = 5\n",
    "n_latent_factors_movie = 8\n",
    "\n",
    "movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "movie_embedding = keras.layers.Embedding(num_movies + 1, n_latent_factors_movie, name='Movie-Embedding')(movie_input)\n",
    "movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "movie_vec = keras.layers.Dropout(0.2)(movie_vec)\n",
    "\n",
    "\n",
    "user_input = keras.layers.Input(shape=[1],name='User')\n",
    "user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(num_users + 1, n_latent_factors_user,name='User-Embedding')(user_input))\n",
    "user_vec = keras.layers.Dropout(0.2)(user_vec)\n",
    "\n",
    "\n",
    "concat = keras.layers.merge([movie_vec, user_vec], mode='concat',name='Concat')\n",
    "concat_dropout = keras.layers.Dropout(0.2)(concat)\n",
    "dense = keras.layers.Dense(200,name='FullyConnected')(concat)\n",
    "dropout_1 = keras.layers.Dropout(0.2,name='Dropout')(dense)\n",
    "dense_2 = keras.layers.Dense(100,name='FullyConnected-1')(concat)\n",
    "dropout_2 = keras.layers.Dropout(0.2,name='Dropout')(dense_2)\n",
    "dense_3 = keras.layers.Dense(50,name='FullyConnected-2')(dense_2)\n",
    "dropout_3 = keras.layers.Dropout(0.2,name='Dropout')(dense_3)\n",
    "dense_4 = keras.layers.Dense(20,name='FullyConnected-3', activation='relu')(dense_3)\n",
    "\n",
    "\n",
    "result = keras.layers.Dense(1, activation='relu',name='Activation')(dense_4)\n",
    "adam = Adam(lr=0.005)\n",
    "model = keras.Model([user_input, movie_input], result)\n",
    "model.compile(optimizer=adam,loss= 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Item (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "User (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Movie-Embedding (Embedding)     (None, 1, 8)         72536       Item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "User-Embedding (Embedding)      (None, 1, 5)         3360        User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "FlattenMovies (Flatten)         (None, 8)            0           Movie-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUsers (Flatten)          (None, 5)            0           User-Embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8)            0           FlattenMovies[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 5)            0           FlattenUsers[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Concat (Merge)                  (None, 13)           0           dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FullyConnected-1 (Dense)        (None, 100)          1400        Concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FullyConnected-2 (Dense)        (None, 50)           5050        FullyConnected-1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FullyConnected-3 (Dense)        (None, 20)           1020        FullyConnected-2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Activation (Dense)              (None, 1)            21          FullyConnected-3[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 83,387\n",
      "Trainable params: 83,387\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      " - 7s - loss: 0.7599\n",
      "Epoch 2/250\n",
      " - 10s - loss: 0.6950\n",
      "Epoch 3/250\n",
      " - 11s - loss: 0.6736\n",
      "Epoch 4/250\n",
      " - 13s - loss: 0.6643\n",
      "Epoch 5/250\n",
      " - 11s - loss: 0.6553\n",
      "Epoch 6/250\n",
      " - 11s - loss: 0.6478\n",
      "Epoch 7/250\n",
      " - 12s - loss: 0.6437\n",
      "Epoch 8/250\n",
      " - 11s - loss: 0.6402\n",
      "Epoch 9/250\n",
      " - 11s - loss: 0.6358\n",
      "Epoch 10/250\n",
      " - 12s - loss: 0.6320\n",
      "Epoch 11/250\n",
      " - 13s - loss: 0.6289\n",
      "Epoch 12/250\n",
      " - 11s - loss: 0.6255\n",
      "Epoch 13/250\n",
      " - 11s - loss: 0.6238\n",
      "Epoch 14/250\n",
      " - 11s - loss: 0.6208\n",
      "Epoch 15/250\n",
      " - 11s - loss: 0.6199\n",
      "Epoch 16/250\n",
      " - 11s - loss: 0.6183\n",
      "Epoch 17/250\n",
      " - 11s - loss: 0.6152\n",
      "Epoch 18/250\n",
      " - 11s - loss: 0.6144\n",
      "Epoch 19/250\n",
      " - 11s - loss: 0.6135\n",
      "Epoch 20/250\n",
      " - 11s - loss: 0.6131\n",
      "Epoch 21/250\n",
      " - 15s - loss: 0.6105\n",
      "Epoch 22/250\n",
      " - 14s - loss: 0.6087\n",
      "Epoch 23/250\n",
      " - 12s - loss: 0.6101\n",
      "Epoch 24/250\n",
      " - 11s - loss: 0.6082\n",
      "Epoch 25/250\n",
      " - 11s - loss: 0.6076\n",
      "Epoch 26/250\n",
      " - 12s - loss: 0.6066\n",
      "Epoch 27/250\n",
      " - 12s - loss: 0.6066\n",
      "Epoch 28/250\n",
      " - 13s - loss: 0.6046\n",
      "Epoch 29/250\n",
      " - 11s - loss: 0.6039\n",
      "Epoch 30/250\n",
      " - 12s - loss: 0.6032\n",
      "Epoch 31/250\n",
      " - 13s - loss: 0.6028\n",
      "Epoch 32/250\n",
      " - 11s - loss: 0.6027\n",
      "Epoch 33/250\n",
      " - 11s - loss: 0.6036\n",
      "Epoch 34/250\n",
      " - 11s - loss: 0.6021\n",
      "Epoch 35/250\n",
      " - 12s - loss: 0.6012\n",
      "Epoch 36/250\n",
      " - 14s - loss: 0.6012\n",
      "Epoch 37/250\n",
      " - 12s - loss: 0.6015\n",
      "Epoch 38/250\n",
      " - 13s - loss: 0.5996\n",
      "Epoch 39/250\n",
      " - 13s - loss: 0.6016\n",
      "Epoch 40/250\n",
      " - 12s - loss: 0.5992\n",
      "Epoch 41/250\n",
      " - 13s - loss: 0.5980\n",
      "Epoch 42/250\n",
      " - 13s - loss: 0.5994\n",
      "Epoch 43/250\n",
      " - 12s - loss: 0.5983\n",
      "Epoch 44/250\n",
      " - 12s - loss: 0.5975\n",
      "Epoch 45/250\n",
      " - 12s - loss: 0.5971\n",
      "Epoch 46/250\n",
      " - 12s - loss: 0.5983\n",
      "Epoch 47/250\n",
      " - 12s - loss: 0.5974\n",
      "Epoch 48/250\n",
      " - 12s - loss: 0.5977\n",
      "Epoch 49/250\n",
      " - 12s - loss: 0.5983\n",
      "Epoch 50/250\n",
      " - 12s - loss: 0.5967\n",
      "Epoch 51/250\n",
      " - 12s - loss: 0.5980\n",
      "Epoch 52/250\n",
      " - 12s - loss: 0.5973\n",
      "Epoch 53/250\n",
      " - 12s - loss: 0.5956\n",
      "Epoch 54/250\n",
      " - 13s - loss: 0.5963\n",
      "Epoch 55/250\n",
      " - 12s - loss: 0.5972\n",
      "Epoch 56/250\n",
      " - 13s - loss: 0.5957\n",
      "Epoch 57/250\n",
      " - 11s - loss: 0.5968\n",
      "Epoch 58/250\n",
      " - 13s - loss: 0.5970\n",
      "Epoch 59/250\n",
      " - 12s - loss: 0.5953\n",
      "Epoch 60/250\n",
      " - 11s - loss: 0.5951\n",
      "Epoch 61/250\n",
      " - 11s - loss: 0.5960\n",
      "Epoch 62/250\n",
      " - 11s - loss: 0.5951\n",
      "Epoch 63/250\n",
      " - 13s - loss: 0.5944\n",
      "Epoch 64/250\n",
      " - 13s - loss: 0.5950\n",
      "Epoch 65/250\n",
      " - 13s - loss: 0.5942\n",
      "Epoch 66/250\n",
      " - 14s - loss: 0.5944\n",
      "Epoch 67/250\n",
      " - 13s - loss: 0.5940\n",
      "Epoch 68/250\n",
      " - 13s - loss: 0.5923\n",
      "Epoch 69/250\n",
      " - 12s - loss: 0.5938\n",
      "Epoch 70/250\n",
      " - 12s - loss: 0.5927\n",
      "Epoch 71/250\n",
      " - 13s - loss: 0.5929\n",
      "Epoch 72/250\n",
      " - 13s - loss: 0.5945\n",
      "Epoch 73/250\n",
      " - 13s - loss: 0.5945\n",
      "Epoch 74/250\n",
      " - 12s - loss: 0.5925\n",
      "Epoch 75/250\n",
      " - 12s - loss: 0.5928\n",
      "Epoch 76/250\n",
      " - 14s - loss: 0.5928\n",
      "Epoch 77/250\n",
      " - 13s - loss: 0.5928\n",
      "Epoch 78/250\n",
      " - 11s - loss: 0.5932\n",
      "Epoch 79/250\n",
      " - 11s - loss: 0.5936\n",
      "Epoch 80/250\n",
      " - 11s - loss: 0.5932\n",
      "Epoch 81/250\n",
      " - 12s - loss: 0.5922\n",
      "Epoch 82/250\n",
      " - 12s - loss: 0.5921\n",
      "Epoch 83/250\n",
      " - 12s - loss: 0.5919\n",
      "Epoch 84/250\n",
      " - 11s - loss: 0.5919\n",
      "Epoch 85/250\n",
      " - 11s - loss: 0.5917\n",
      "Epoch 86/250\n",
      " - 12s - loss: 0.5916\n",
      "Epoch 87/250\n",
      " - 14s - loss: 0.5910\n",
      "Epoch 88/250\n",
      " - 13s - loss: 0.5923\n",
      "Epoch 89/250\n",
      " - 11s - loss: 0.5913\n",
      "Epoch 90/250\n",
      " - 12s - loss: 0.5932\n",
      "Epoch 91/250\n",
      " - 13s - loss: 0.5905\n",
      "Epoch 92/250\n",
      " - 13s - loss: 0.5909\n",
      "Epoch 93/250\n",
      " - 13s - loss: 0.5907\n",
      "Epoch 94/250\n",
      " - 14s - loss: 0.5899\n",
      "Epoch 95/250\n",
      " - 14s - loss: 0.5910\n",
      "Epoch 96/250\n",
      " - 14s - loss: 0.5910\n",
      "Epoch 97/250\n",
      " - 14s - loss: 0.5902\n",
      "Epoch 98/250\n",
      " - 15s - loss: 0.5913\n",
      "Epoch 99/250\n",
      " - 13s - loss: 0.5908\n",
      "Epoch 100/250\n",
      " - 13s - loss: 0.5902\n",
      "Epoch 101/250\n",
      " - 13s - loss: 0.5901\n",
      "Epoch 102/250\n",
      " - 12s - loss: 0.5897\n",
      "Epoch 103/250\n",
      " - 12s - loss: 0.5904\n",
      "Epoch 104/250\n",
      " - 12s - loss: 0.5900\n",
      "Epoch 105/250\n",
      " - 14s - loss: 0.5907\n",
      "Epoch 106/250\n",
      " - 12s - loss: 0.5904\n",
      "Epoch 107/250\n",
      " - 12s - loss: 0.5893\n",
      "Epoch 108/250\n",
      " - 12s - loss: 0.5911\n",
      "Epoch 109/250\n",
      " - 12s - loss: 0.5905\n",
      "Epoch 110/250\n",
      " - 12s - loss: 0.5903\n",
      "Epoch 111/250\n",
      " - 14s - loss: 0.5899\n",
      "Epoch 112/250\n",
      " - 14s - loss: 0.5898\n",
      "Epoch 113/250\n",
      " - 14s - loss: 0.5894\n",
      "Epoch 114/250\n",
      " - 14s - loss: 0.5898\n",
      "Epoch 115/250\n",
      " - 14s - loss: 0.5900\n",
      "Epoch 116/250\n",
      " - 14s - loss: 0.5886\n",
      "Epoch 117/250\n",
      " - 14s - loss: 0.5893\n",
      "Epoch 118/250\n",
      " - 14s - loss: 0.5895\n",
      "Epoch 119/250\n",
      " - 13s - loss: 0.5887\n",
      "Epoch 120/250\n",
      " - 13s - loss: 0.5901\n",
      "Epoch 121/250\n",
      " - 13s - loss: 0.5907\n",
      "Epoch 122/250\n",
      " - 12s - loss: 0.5893\n",
      "Epoch 123/250\n",
      " - 12s - loss: 0.5887\n",
      "Epoch 124/250\n",
      " - 12s - loss: 0.5887\n",
      "Epoch 125/250\n",
      " - 13s - loss: 0.5902\n",
      "Epoch 126/250\n",
      " - 12s - loss: 0.5900\n",
      "Epoch 127/250\n",
      " - 12s - loss: 0.5896\n",
      "Epoch 128/250\n",
      " - 13s - loss: 0.5888\n",
      "Epoch 129/250\n",
      " - 12s - loss: 0.5898\n",
      "Epoch 130/250\n",
      " - 12s - loss: 0.5884\n",
      "Epoch 131/250\n",
      " - 12s - loss: 0.5892\n",
      "Epoch 132/250\n",
      " - 12s - loss: 0.5897\n",
      "Epoch 133/250\n",
      " - 12s - loss: 0.5888\n",
      "Epoch 134/250\n",
      " - 12s - loss: 0.5878\n",
      "Epoch 135/250\n",
      " - 12s - loss: 0.5896\n",
      "Epoch 136/250\n",
      " - 14s - loss: 0.5884\n",
      "Epoch 137/250\n",
      " - 13s - loss: 0.5897\n",
      "Epoch 138/250\n",
      " - 13s - loss: 0.5885\n",
      "Epoch 139/250\n",
      " - 13s - loss: 0.5885\n",
      "Epoch 140/250\n",
      " - 12s - loss: 0.5887\n",
      "Epoch 141/250\n",
      " - 14s - loss: 0.5881\n",
      "Epoch 142/250\n",
      " - 12s - loss: 0.5876\n",
      "Epoch 143/250\n",
      " - 12s - loss: 0.5890\n",
      "Epoch 144/250\n",
      " - 12s - loss: 0.5887\n",
      "Epoch 145/250\n",
      " - 12s - loss: 0.5875\n",
      "Epoch 146/250\n",
      " - 12s - loss: 0.5878\n",
      "Epoch 147/250\n",
      " - 12s - loss: 0.5876\n",
      "Epoch 148/250\n",
      " - 13s - loss: 0.5886\n",
      "Epoch 149/250\n",
      " - 12s - loss: 0.5878\n",
      "Epoch 150/250\n",
      " - 12s - loss: 0.5881\n",
      "Epoch 151/250\n",
      " - 12s - loss: 0.5884\n",
      "Epoch 152/250\n",
      " - 12s - loss: 0.5872\n",
      "Epoch 153/250\n",
      " - 12s - loss: 0.5878\n",
      "Epoch 154/250\n",
      " - 12s - loss: 0.5876\n",
      "Epoch 155/250\n",
      " - 12s - loss: 0.5892\n",
      "Epoch 156/250\n",
      " - 12s - loss: 0.5871\n",
      "Epoch 157/250\n",
      " - 12s - loss: 0.5881\n",
      "Epoch 158/250\n",
      " - 12s - loss: 0.5869\n",
      "Epoch 159/250\n",
      " - 12s - loss: 0.5880\n",
      "Epoch 160/250\n",
      " - 12s - loss: 0.5874\n",
      "Epoch 161/250\n",
      " - 12s - loss: 0.5874\n",
      "Epoch 162/250\n",
      " - 13s - loss: 0.5874\n",
      "Epoch 163/250\n",
      " - 12s - loss: 0.5876\n",
      "Epoch 164/250\n",
      " - 13s - loss: 0.5869\n",
      "Epoch 165/250\n",
      " - 14s - loss: 0.5877\n",
      "Epoch 166/250\n",
      " - 14s - loss: 0.5873\n",
      "Epoch 167/250\n",
      " - 14s - loss: 0.5868\n",
      "Epoch 168/250\n",
      " - 13s - loss: 0.5864\n",
      "Epoch 169/250\n",
      " - 12s - loss: 0.5874\n",
      "Epoch 170/250\n",
      " - 12s - loss: 0.5862\n",
      "Epoch 171/250\n",
      " - 12s - loss: 0.5872\n",
      "Epoch 172/250\n",
      " - 14s - loss: 0.5877\n",
      "Epoch 173/250\n",
      " - 14s - loss: 0.5865\n",
      "Epoch 174/250\n",
      " - 14s - loss: 0.5883\n",
      "Epoch 175/250\n",
      " - 14s - loss: 0.5869\n",
      "Epoch 176/250\n",
      " - 14s - loss: 0.5874\n",
      "Epoch 177/250\n",
      " - 14s - loss: 0.5869\n",
      "Epoch 178/250\n",
      " - 13s - loss: 0.5890\n",
      "Epoch 179/250\n",
      " - 12s - loss: 0.5859\n",
      "Epoch 180/250\n",
      " - 12s - loss: 0.5875\n",
      "Epoch 181/250\n",
      " - 14s - loss: 0.5873\n",
      "Epoch 182/250\n",
      " - 14s - loss: 0.5862\n",
      "Epoch 183/250\n",
      " - 14s - loss: 0.5881\n",
      "Epoch 184/250\n",
      " - 14s - loss: 0.5871\n",
      "Epoch 185/250\n",
      " - 14s - loss: 0.5868\n",
      "Epoch 186/250\n",
      " - 14s - loss: 0.5873\n",
      "Epoch 187/250\n",
      " - 14s - loss: 0.5867\n",
      "Epoch 188/250\n",
      " - 14s - loss: 0.5866\n",
      "Epoch 189/250\n",
      " - 14s - loss: 0.5875\n",
      "Epoch 190/250\n",
      " - 14s - loss: 0.5875\n",
      "Epoch 191/250\n",
      " - 14s - loss: 0.5866\n",
      "Epoch 192/250\n",
      " - 14s - loss: 0.5873\n",
      "Epoch 193/250\n",
      " - 14s - loss: 0.5857\n",
      "Epoch 194/250\n",
      " - 14s - loss: 0.5870\n",
      "Epoch 195/250\n",
      " - 14s - loss: 0.5850\n",
      "Epoch 196/250\n",
      " - 12s - loss: 0.5876\n",
      "Epoch 197/250\n",
      " - 12s - loss: 0.5866\n",
      "Epoch 198/250\n",
      " - 12s - loss: 0.5871\n",
      "Epoch 199/250\n",
      " - 12s - loss: 0.5850\n",
      "Epoch 200/250\n",
      " - 12s - loss: 0.5853\n",
      "Epoch 201/250\n",
      " - 12s - loss: 0.5873\n",
      "Epoch 202/250\n",
      " - 12s - loss: 0.5860\n",
      "Epoch 203/250\n",
      " - 12s - loss: 0.5869\n",
      "Epoch 204/250\n",
      " - 12s - loss: 0.5859\n",
      "Epoch 205/250\n",
      " - 12s - loss: 0.5863\n",
      "Epoch 206/250\n",
      " - 12s - loss: 0.5874\n",
      "Epoch 207/250\n",
      " - 12s - loss: 0.5872\n",
      "Epoch 208/250\n",
      " - 12s - loss: 0.5858\n",
      "Epoch 209/250\n",
      " - 12s - loss: 0.5858\n",
      "Epoch 210/250\n",
      " - 13s - loss: 0.5862\n",
      "Epoch 211/250\n",
      " - 12s - loss: 0.5869\n",
      "Epoch 212/250\n",
      " - 13s - loss: 0.5856\n",
      "Epoch 213/250\n",
      " - 11s - loss: 0.5858\n",
      "Epoch 214/250\n",
      " - 11s - loss: 0.5854\n",
      "Epoch 215/250\n",
      " - 12s - loss: 0.5866\n",
      "Epoch 216/250\n",
      " - 13s - loss: 0.5871\n",
      "Epoch 217/250\n",
      " - 13s - loss: 0.5864\n",
      "Epoch 218/250\n",
      " - 11s - loss: 0.5861\n",
      "Epoch 219/250\n",
      " - 11s - loss: 0.5867\n",
      "Epoch 220/250\n",
      " - 12s - loss: 0.5856\n",
      "Epoch 221/250\n",
      " - 12s - loss: 0.5856\n",
      "Epoch 222/250\n",
      " - 11s - loss: 0.5861\n",
      "Epoch 223/250\n",
      " - 11s - loss: 0.5863\n",
      "Epoch 224/250\n",
      " - 12s - loss: 0.5865\n",
      "Epoch 225/250\n",
      " - 12s - loss: 0.5863\n",
      "Epoch 226/250\n",
      " - 12s - loss: 0.5858\n",
      "Epoch 227/250\n",
      " - 12s - loss: 0.5849\n",
      "Epoch 228/250\n",
      " - 14s - loss: 0.5860\n",
      "Epoch 229/250\n",
      " - 13s - loss: 0.5857\n",
      "Epoch 230/250\n",
      " - 12s - loss: 0.5852\n",
      "Epoch 231/250\n",
      " - 13s - loss: 0.5862\n",
      "Epoch 232/250\n",
      " - 11s - loss: 0.5867\n",
      "Epoch 233/250\n",
      " - 11s - loss: 0.5866\n",
      "Epoch 234/250\n",
      " - 13s - loss: 0.5866\n",
      "Epoch 235/250\n",
      " - 14s - loss: 0.5870\n",
      "Epoch 236/250\n",
      " - 13s - loss: 0.5851\n",
      "Epoch 237/250\n",
      " - 12s - loss: 0.5851\n",
      "Epoch 238/250\n",
      " - 12s - loss: 0.5844\n",
      "Epoch 239/250\n",
      " - 12s - loss: 0.5861\n",
      "Epoch 240/250\n",
      " - 13s - loss: 0.5862\n",
      "Epoch 241/250\n",
      " - 12s - loss: 0.5858\n",
      "Epoch 242/250\n",
      " - 12s - loss: 0.5854\n",
      "Epoch 243/250\n",
      " - 12s - loss: 0.5853\n",
      "Epoch 244/250\n",
      " - 11s - loss: 0.5868\n",
      "Epoch 245/250\n",
      " - 11s - loss: 0.5868\n",
      "Epoch 246/250\n",
      " - 13s - loss: 0.5853\n",
      "Epoch 247/250\n",
      " - 12s - loss: 0.5864\n",
      "Epoch 248/250\n",
      " - 12s - loss: 0.5868\n",
      "Epoch 249/250\n",
      " - 11s - loss: 0.5853\n",
      "Epoch 250/250\n",
      " - 12s - loss: 0.5856\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training = model.fit(x=[train.userId, train.movieId], y=train.rating, epochs=250,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fe687246ef0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEKCAYAAADNSVhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nj4iIRJ3CR0REou7/AyxgITOgRmiaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe687146ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(training.history['loss']).plot(logy=True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_hat = np.round(model.predict([test.userId, test.movieId]),decimals=0)\n",
    "\n",
    "y_true = test.rating\n",
    "y_true = np.array(test.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66931653417329129"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will include the \"extra\" factors of users and movies into the input : \n",
    "To do so, we can learn *embeddings* for the extra factors we wish to include. <br/> The vector embeddings of the extra factors can be then be simply stacked with the user ID or movie ID vectors.<br/> Another way of doing it is to include another input layer dedicated to extra factors. Lets include an extra input layer for the extra factors and build the neural network. To compare the performance we will keep the parameters of the previous neural network unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies.csv',sep=',')\n",
    "movies['genre'] = movies.genres.str.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>[Adventure, Children, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \\\n",
       "0  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "1                   Adventure|Children|Fantasy   \n",
       "2                               Comedy|Romance   \n",
       "3                         Comedy|Drama|Romance   \n",
       "4                                       Comedy   \n",
       "\n",
       "                                               genre  \n",
       "0  [Adventure, Animation, Children, Comedy, Fantasy]  \n",
       "1                     [Adventure, Children, Fantasy]  \n",
       "2                                  [Comedy, Romance]  \n",
       "3                           [Comedy, Drama, Romance]  \n",
       "4                                           [Comedy]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9115</th>\n",
       "      <th>9116</th>\n",
       "      <th>9117</th>\n",
       "      <th>9118</th>\n",
       "      <th>9119</th>\n",
       "      <th>9120</th>\n",
       "      <th>9121</th>\n",
       "      <th>9122</th>\n",
       "      <th>9123</th>\n",
       "      <th>9124</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>9115</td>\n",
       "      <td>9116</td>\n",
       "      <td>9117</td>\n",
       "      <td>9118</td>\n",
       "      <td>9119</td>\n",
       "      <td>9120</td>\n",
       "      <td>9121</td>\n",
       "      <td>9122</td>\n",
       "      <td>9123</td>\n",
       "      <td>9124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genres</th>\n",
       "      <td>328</td>\n",
       "      <td>393</td>\n",
       "      <td>686</td>\n",
       "      <td>645</td>\n",
       "      <td>595</td>\n",
       "      <td>241</td>\n",
       "      <td>686</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>803</td>\n",
       "      <td>110</td>\n",
       "      <td>761</td>\n",
       "      <td>761</td>\n",
       "      <td>892</td>\n",
       "      <td>454</td>\n",
       "      <td>105</td>\n",
       "      <td>748</td>\n",
       "      <td>595</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 9125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2     3     4     5     6     7     8     9     ...   \\\n",
       "movieId     0     1     2     3     4     5     6     7     8     9  ...    \n",
       "genres    328   393   686   645   595   241   686   376     1   123  ...    \n",
       "\n",
       "         9115  9116  9117  9118  9119  9120  9121  9122  9123  9124  \n",
       "movieId  9115  9116  9117  9118  9119  9120  9121  9122  9123  9124  \n",
       "genres    803   110   761   761   892   454   105   748   595   748  \n",
       "\n",
       "[2 rows x 9125 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.movieId = movies.movieId.astype('category').cat.codes.values #Numpy array for item id's\n",
    "movies.genres = movies.genres.astype('category').cat.codes.values\n",
    "movies.movieId.unique()\n",
    "movies.head()\n",
    "df_genre = pd.DataFrame([movies.movieId,movies.genres])\n",
    "movies.head()\n",
    "df_genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70088</th>\n",
       "      <td>483</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851345204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89327</th>\n",
       "      <td>595</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1145034973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76593</th>\n",
       "      <td>529</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>879014231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59530</th>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1165547529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63772</th>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>859210690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "70088     483        0     3.0   851345204\n",
       "89327     595        0     3.5  1145034973\n",
       "76593     529        0     5.0   879014231\n",
       "59530     430        0     4.5  1165547529\n",
       "63772     458        0     5.0   859210690"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted_movieId=df.sort_values('movieId')\n",
    "df_sorted_movieId.head()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "No common columns to perform merge on",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-df4d0cf78912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_sorted_movieId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_genre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ankit/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m   4818\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4819\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4820\u001b[0;31m                      copy=copy, indicator=indicator)\n\u001b[0m\u001b[1;32m   4821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4822\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ankit/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m     51\u001b[0m                          \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                          copy=copy, indicator=indicator)\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ankit/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_specification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# note this function has side effects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ankit/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_validate_specification\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    926\u001b[0m                     self.right.columns)\n\u001b[1;32m    927\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_cols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mMergeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No common columns to perform merge on'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcommon_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                     raise MergeError(\"Data columns not unique: %s\"\n",
      "\u001b[0;31mMergeError\u001b[0m: No common columns to perform merge on"
     ]
    }
   ],
   "source": [
    "df_sorted_movieId.merge(df_genre,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId     int16\n",
       "title      object\n",
       "genres      int16\n",
       "genre      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_movie_genre=len(movies.genres.unique())\n",
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Creating a sample sequential model\"\n",
    "model = Sequential()\n",
    "\n",
    "\"Embedding layer > input_dim = dimension of input vector \"\n",
    "\"                  output_dim = Number of latent features \"\n",
    "model.add(keras.layers.Embedding(input_dim=num_movie_genre+1,output_dim=5 , input_length= 1))\n",
    "\"the model will take as input an integer matrix of size (batch, input_length).\"\n",
    "\" We input the item_id in the range 1 - 9066 of shape [1] and get output of shape [1 * n_latent_factors]\"\n",
    "input_array =movies.genres\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.02087205,  0.0175561 , -0.03101997,  0.02893331, -0.02056722]],\n",
       "\n",
       "       [[-0.01480265, -0.00799886, -0.01628273, -0.01967268, -0.04088835]],\n",
       "\n",
       "       [[ 0.02612372,  0.01650136, -0.01789467,  0.04688015, -0.03115863]],\n",
       "\n",
       "       ..., \n",
       "       [[-0.00062101, -0.0447359 ,  0.00849695,  0.0392585 ,  0.04257723]],\n",
       "\n",
       "       [[ 0.02054017, -0.01327827, -0.00536516, -0.03820894,  0.04680843]],\n",
       "\n",
       "       [[-0.00062101, -0.0447359 ,  0.00849695,  0.0392585 ,  0.04257723]]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
